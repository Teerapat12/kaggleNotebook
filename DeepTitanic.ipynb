{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['name_length'] = df['Name'].apply(len)\n",
    "df['ticket_length'] = df['Ticket'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','name_length','ticket_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Sex2Num(sex):\n",
    "    if(sex=='male'):return 1\n",
    "    elif(sex=='female'):return 2\n",
    "    else: return 0\n",
    "df['Sex'] = df['Sex'].apply(Sex2Num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    C    Q    S\n",
       "0    0.0  0.0  0.0  1.0\n",
       "1    0.0  1.0  0.0  0.0\n",
       "2    0.0  0.0  0.0  1.0\n",
       "3    0.0  0.0  0.0  1.0\n",
       "4    0.0  0.0  0.0  1.0\n",
       "5    0.0  0.0  1.0  0.0\n",
       "6    0.0  0.0  0.0  1.0\n",
       "7    0.0  0.0  0.0  1.0\n",
       "8    0.0  0.0  0.0  1.0\n",
       "9    0.0  1.0  0.0  0.0\n",
       "10   0.0  0.0  0.0  1.0\n",
       "11   0.0  0.0  0.0  1.0\n",
       "12   0.0  0.0  0.0  1.0\n",
       "13   0.0  0.0  0.0  1.0\n",
       "14   0.0  0.0  0.0  1.0\n",
       "15   0.0  0.0  0.0  1.0\n",
       "16   0.0  0.0  1.0  0.0\n",
       "17   0.0  0.0  0.0  1.0\n",
       "18   0.0  0.0  0.0  1.0\n",
       "19   0.0  1.0  0.0  0.0\n",
       "20   0.0  0.0  0.0  1.0\n",
       "21   0.0  0.0  0.0  1.0\n",
       "22   0.0  0.0  1.0  0.0\n",
       "23   0.0  0.0  0.0  1.0\n",
       "24   0.0  0.0  0.0  1.0\n",
       "25   0.0  0.0  0.0  1.0\n",
       "26   0.0  1.0  0.0  0.0\n",
       "27   0.0  0.0  0.0  1.0\n",
       "28   0.0  0.0  1.0  0.0\n",
       "29   0.0  0.0  0.0  1.0\n",
       "..   ...  ...  ...  ...\n",
       "861  0.0  0.0  0.0  1.0\n",
       "862  0.0  0.0  0.0  1.0\n",
       "863  0.0  0.0  0.0  1.0\n",
       "864  0.0  0.0  0.0  1.0\n",
       "865  0.0  0.0  0.0  1.0\n",
       "866  0.0  1.0  0.0  0.0\n",
       "867  0.0  0.0  0.0  1.0\n",
       "868  0.0  0.0  0.0  1.0\n",
       "869  0.0  0.0  0.0  1.0\n",
       "870  0.0  0.0  0.0  1.0\n",
       "871  0.0  0.0  0.0  1.0\n",
       "872  0.0  0.0  0.0  1.0\n",
       "873  0.0  0.0  0.0  1.0\n",
       "874  0.0  1.0  0.0  0.0\n",
       "875  0.0  1.0  0.0  0.0\n",
       "876  0.0  0.0  0.0  1.0\n",
       "877  0.0  0.0  0.0  1.0\n",
       "878  0.0  0.0  0.0  1.0\n",
       "879  0.0  1.0  0.0  0.0\n",
       "880  0.0  0.0  0.0  1.0\n",
       "881  0.0  0.0  0.0  1.0\n",
       "882  0.0  0.0  0.0  1.0\n",
       "883  0.0  0.0  0.0  1.0\n",
       "884  0.0  0.0  0.0  1.0\n",
       "885  0.0  0.0  1.0  0.0\n",
       "886  0.0  0.0  0.0  1.0\n",
       "887  0.0  0.0  0.0  1.0\n",
       "888  0.0  0.0  0.0  1.0\n",
       "889  0.0  1.0  0.0  0.0\n",
       "890  0.0  0.0  1.0  0.0\n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=9, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32,  activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation = 'tanh'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation = 'tanh'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(32,  activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation = 'tanh'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation = 'tanh'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 668 samples, validate on 223 samples\n",
      "Epoch 1/100\n",
      "668/668 [==============================] - 1s - loss: 0.7009 - acc: 0.4835 - val_loss: 0.6795 - val_acc: 0.6637\n",
      "Epoch 2/100\n",
      "668/668 [==============================] - 0s - loss: 0.6859 - acc: 0.5749 - val_loss: 0.6599 - val_acc: 0.6413\n",
      "Epoch 3/100\n",
      "668/668 [==============================] - 0s - loss: 0.6806 - acc: 0.6003 - val_loss: 0.6456 - val_acc: 0.6323\n",
      "Epoch 4/100\n",
      "668/668 [==============================] - 0s - loss: 0.6754 - acc: 0.6093 - val_loss: 0.6502 - val_acc: 0.6323\n",
      "Epoch 5/100\n",
      "668/668 [==============================] - 0s - loss: 0.6811 - acc: 0.5868 - val_loss: 0.6525 - val_acc: 0.6323\n",
      "Epoch 6/100\n",
      "668/668 [==============================] - 0s - loss: 0.6836 - acc: 0.6018 - val_loss: 0.6495 - val_acc: 0.6323\n",
      "Epoch 7/100\n",
      "668/668 [==============================] - 0s - loss: 0.6796 - acc: 0.5734 - val_loss: 0.6472 - val_acc: 0.6323\n",
      "Epoch 8/100\n",
      "668/668 [==============================] - 0s - loss: 0.6669 - acc: 0.6108 - val_loss: 0.6394 - val_acc: 0.6323\n",
      "Epoch 9/100\n",
      "668/668 [==============================] - 0s - loss: 0.6705 - acc: 0.6108 - val_loss: 0.6374 - val_acc: 0.6323\n",
      "Epoch 10/100\n",
      "668/668 [==============================] - 0s - loss: 0.6691 - acc: 0.6213 - val_loss: 0.6419 - val_acc: 0.6323\n",
      "Epoch 11/100\n",
      "668/668 [==============================] - 0s - loss: 0.6769 - acc: 0.6048 - val_loss: 0.6419 - val_acc: 0.6323\n",
      "Epoch 12/100\n",
      "668/668 [==============================] - 0s - loss: 0.6647 - acc: 0.6138 - val_loss: 0.6431 - val_acc: 0.6323\n",
      "Epoch 13/100\n",
      "668/668 [==============================] - 0s - loss: 0.6839 - acc: 0.5943 - val_loss: 0.6482 - val_acc: 0.6323\n",
      "Epoch 14/100\n",
      "668/668 [==============================] - 0s - loss: 0.6734 - acc: 0.5943 - val_loss: 0.6474 - val_acc: 0.6323\n",
      "Epoch 15/100\n",
      "668/668 [==============================] - 0s - loss: 0.6778 - acc: 0.6093 - val_loss: 0.6478 - val_acc: 0.6323\n",
      "Epoch 16/100\n",
      "668/668 [==============================] - 0s - loss: 0.6709 - acc: 0.6078 - val_loss: 0.6438 - val_acc: 0.6323\n",
      "Epoch 17/100\n",
      "668/668 [==============================] - 0s - loss: 0.6736 - acc: 0.6048 - val_loss: 0.6472 - val_acc: 0.6323\n",
      "Epoch 18/100\n",
      "668/668 [==============================] - 0s - loss: 0.6659 - acc: 0.6063 - val_loss: 0.6394 - val_acc: 0.6323\n",
      "Epoch 19/100\n",
      "668/668 [==============================] - 0s - loss: 0.6781 - acc: 0.6078 - val_loss: 0.6429 - val_acc: 0.6323\n",
      "Epoch 20/100\n",
      "668/668 [==============================] - 0s - loss: 0.6648 - acc: 0.6198 - val_loss: 0.6391 - val_acc: 0.6323\n",
      "Epoch 21/100\n",
      "668/668 [==============================] - 0s - loss: 0.6640 - acc: 0.6033 - val_loss: 0.6491 - val_acc: 0.6323\n",
      "Epoch 22/100\n",
      "668/668 [==============================] - 0s - loss: 0.6603 - acc: 0.6033 - val_loss: 0.6394 - val_acc: 0.6323\n",
      "Epoch 23/100\n",
      "668/668 [==============================] - 0s - loss: 0.6662 - acc: 0.6003 - val_loss: 0.6352 - val_acc: 0.6323\n",
      "Epoch 24/100\n",
      "668/668 [==============================] - 0s - loss: 0.6598 - acc: 0.6153 - val_loss: 0.6279 - val_acc: 0.6323\n",
      "Epoch 25/100\n",
      "668/668 [==============================] - 0s - loss: 0.6723 - acc: 0.6018 - val_loss: 0.6285 - val_acc: 0.6323\n",
      "Epoch 26/100\n",
      "668/668 [==============================] - 0s - loss: 0.6710 - acc: 0.6138 - val_loss: 0.6332 - val_acc: 0.6323\n",
      "Epoch 27/100\n",
      "668/668 [==============================] - 0s - loss: 0.6672 - acc: 0.6048 - val_loss: 0.6381 - val_acc: 0.6323\n",
      "Epoch 28/100\n",
      "668/668 [==============================] - 0s - loss: 0.6625 - acc: 0.6078 - val_loss: 0.6400 - val_acc: 0.6323\n",
      "Epoch 29/100\n",
      "668/668 [==============================] - 0s - loss: 0.6641 - acc: 0.6003 - val_loss: 0.6352 - val_acc: 0.6323\n",
      "Epoch 30/100\n",
      "668/668 [==============================] - 0s - loss: 0.6632 - acc: 0.6138 - val_loss: 0.6315 - val_acc: 0.6323\n",
      "Epoch 31/100\n",
      "668/668 [==============================] - 0s - loss: 0.6671 - acc: 0.5958 - val_loss: 0.6318 - val_acc: 0.6323\n",
      "Epoch 32/100\n",
      "668/668 [==============================] - 0s - loss: 0.6666 - acc: 0.6213 - val_loss: 0.6318 - val_acc: 0.6323\n",
      "Epoch 33/100\n",
      "668/668 [==============================] - 0s - loss: 0.6595 - acc: 0.6078 - val_loss: 0.6320 - val_acc: 0.6323\n",
      "Epoch 34/100\n",
      "668/668 [==============================] - 0s - loss: 0.6479 - acc: 0.6332 - val_loss: 0.6266 - val_acc: 0.6771\n",
      "Epoch 35/100\n",
      "668/668 [==============================] - 0s - loss: 0.6503 - acc: 0.6198 - val_loss: 0.6201 - val_acc: 0.6861\n",
      "Epoch 36/100\n",
      "668/668 [==============================] - 0s - loss: 0.6663 - acc: 0.6033 - val_loss: 0.6180 - val_acc: 0.6547\n",
      "Epoch 37/100\n",
      "668/668 [==============================] - 0s - loss: 0.6595 - acc: 0.6272 - val_loss: 0.6190 - val_acc: 0.6323\n",
      "Epoch 38/100\n",
      "668/668 [==============================] - 0s - loss: 0.6525 - acc: 0.6287 - val_loss: 0.6165 - val_acc: 0.6771\n",
      "Epoch 39/100\n",
      "668/668 [==============================] - 0s - loss: 0.6596 - acc: 0.6078 - val_loss: 0.6139 - val_acc: 0.6906\n",
      "Epoch 40/100\n",
      "668/668 [==============================] - 0s - loss: 0.6549 - acc: 0.6272 - val_loss: 0.6139 - val_acc: 0.7040\n",
      "Epoch 41/100\n",
      "668/668 [==============================] - 0s - loss: 0.6523 - acc: 0.6377 - val_loss: 0.6120 - val_acc: 0.7040\n",
      "Epoch 42/100\n",
      "668/668 [==============================] - 0s - loss: 0.6628 - acc: 0.6287 - val_loss: 0.6146 - val_acc: 0.6996\n",
      "Epoch 43/100\n",
      "668/668 [==============================] - 0s - loss: 0.6527 - acc: 0.6317 - val_loss: 0.6131 - val_acc: 0.6996\n",
      "Epoch 44/100\n",
      "668/668 [==============================] - 0s - loss: 0.6505 - acc: 0.6257 - val_loss: 0.6130 - val_acc: 0.7040\n",
      "Epoch 45/100\n",
      "668/668 [==============================] - 0s - loss: 0.6616 - acc: 0.6183 - val_loss: 0.6148 - val_acc: 0.7085\n",
      "Epoch 46/100\n",
      "668/668 [==============================] - 0s - loss: 0.6580 - acc: 0.6108 - val_loss: 0.6158 - val_acc: 0.6906\n",
      "Epoch 47/100\n",
      "668/668 [==============================] - 0s - loss: 0.6609 - acc: 0.6347 - val_loss: 0.6177 - val_acc: 0.7085\n",
      "Epoch 48/100\n",
      "668/668 [==============================] - 0s - loss: 0.6515 - acc: 0.6228 - val_loss: 0.6158 - val_acc: 0.6996\n",
      "Epoch 49/100\n",
      "668/668 [==============================] - 0s - loss: 0.6569 - acc: 0.6228 - val_loss: 0.6149 - val_acc: 0.6816\n",
      "Epoch 50/100\n",
      "668/668 [==============================] - 0s - loss: 0.6506 - acc: 0.6257 - val_loss: 0.6121 - val_acc: 0.7040\n",
      "Epoch 51/100\n",
      "668/668 [==============================] - 0s - loss: 0.6634 - acc: 0.6377 - val_loss: 0.6198 - val_acc: 0.6906\n",
      "Epoch 52/100\n",
      "668/668 [==============================] - 0s - loss: 0.6542 - acc: 0.6257 - val_loss: 0.6193 - val_acc: 0.7175\n",
      "Epoch 53/100\n",
      "668/668 [==============================] - 0s - loss: 0.6419 - acc: 0.6377 - val_loss: 0.6165 - val_acc: 0.7085\n",
      "Epoch 54/100\n",
      "668/668 [==============================] - 0s - loss: 0.6474 - acc: 0.6362 - val_loss: 0.6113 - val_acc: 0.7130\n",
      "Epoch 55/100\n",
      "668/668 [==============================] - 0s - loss: 0.6410 - acc: 0.6392 - val_loss: 0.6082 - val_acc: 0.7085\n",
      "Epoch 56/100\n",
      "668/668 [==============================] - 0s - loss: 0.6571 - acc: 0.6302 - val_loss: 0.6079 - val_acc: 0.7040\n",
      "Epoch 57/100\n",
      "668/668 [==============================] - 0s - loss: 0.6377 - acc: 0.6422 - val_loss: 0.6066 - val_acc: 0.6861\n",
      "Epoch 58/100\n",
      "668/668 [==============================] - 0s - loss: 0.6497 - acc: 0.6482 - val_loss: 0.6038 - val_acc: 0.6816\n",
      "Epoch 59/100\n",
      "668/668 [==============================] - 0s - loss: 0.6477 - acc: 0.6422 - val_loss: 0.6089 - val_acc: 0.6816\n",
      "Epoch 60/100\n",
      "668/668 [==============================] - 0s - loss: 0.6411 - acc: 0.6512 - val_loss: 0.6043 - val_acc: 0.6816\n",
      "Epoch 61/100\n",
      "668/668 [==============================] - 0s - loss: 0.6447 - acc: 0.6407 - val_loss: 0.6028 - val_acc: 0.6816\n",
      "Epoch 62/100\n",
      "668/668 [==============================] - 0s - loss: 0.6426 - acc: 0.6512 - val_loss: 0.5993 - val_acc: 0.6816\n",
      "Epoch 63/100\n",
      "668/668 [==============================] - 0s - loss: 0.6308 - acc: 0.6617 - val_loss: 0.5951 - val_acc: 0.6771\n",
      "Epoch 64/100\n",
      "668/668 [==============================] - 0s - loss: 0.6429 - acc: 0.6512 - val_loss: 0.5912 - val_acc: 0.6771\n",
      "Epoch 65/100\n",
      "668/668 [==============================] - 0s - loss: 0.6443 - acc: 0.6407 - val_loss: 0.5940 - val_acc: 0.6771\n",
      "Epoch 66/100\n",
      "668/668 [==============================] - 0s - loss: 0.6475 - acc: 0.6272 - val_loss: 0.5932 - val_acc: 0.6726\n",
      "Epoch 67/100\n",
      "668/668 [==============================] - 0s - loss: 0.6426 - acc: 0.6063 - val_loss: 0.5936 - val_acc: 0.6771\n",
      "Epoch 68/100\n",
      "668/668 [==============================] - 0s - loss: 0.6375 - acc: 0.6452 - val_loss: 0.5918 - val_acc: 0.6816\n",
      "Epoch 69/100\n",
      "668/668 [==============================] - 0s - loss: 0.6490 - acc: 0.6287 - val_loss: 0.5920 - val_acc: 0.6771\n",
      "Epoch 70/100\n",
      "668/668 [==============================] - 0s - loss: 0.6319 - acc: 0.6063 - val_loss: 0.5902 - val_acc: 0.6816\n",
      "Epoch 71/100\n",
      "668/668 [==============================] - 0s - loss: 0.6333 - acc: 0.6422 - val_loss: 0.5879 - val_acc: 0.6816\n",
      "Epoch 72/100\n",
      "668/668 [==============================] - 0s - loss: 0.6293 - acc: 0.6392 - val_loss: 0.5866 - val_acc: 0.6816\n",
      "Epoch 73/100\n",
      "668/668 [==============================] - 0s - loss: 0.6317 - acc: 0.6392 - val_loss: 0.5880 - val_acc: 0.6861\n",
      "Epoch 74/100\n",
      "668/668 [==============================] - 0s - loss: 0.6263 - acc: 0.6332 - val_loss: 0.5874 - val_acc: 0.7040\n",
      "Epoch 75/100\n",
      "668/668 [==============================] - 0s - loss: 0.6361 - acc: 0.6377 - val_loss: 0.5854 - val_acc: 0.6951\n",
      "Epoch 76/100\n",
      "668/668 [==============================] - 0s - loss: 0.6255 - acc: 0.6781 - val_loss: 0.5863 - val_acc: 0.6951\n",
      "Epoch 77/100\n",
      "668/668 [==============================] - 0s - loss: 0.6275 - acc: 0.6542 - val_loss: 0.5861 - val_acc: 0.6996\n",
      "Epoch 78/100\n",
      "668/668 [==============================] - 0s - loss: 0.6298 - acc: 0.6437 - val_loss: 0.5798 - val_acc: 0.7040\n",
      "Epoch 79/100\n",
      "668/668 [==============================] - 0s - loss: 0.6420 - acc: 0.6287 - val_loss: 0.5797 - val_acc: 0.6951\n",
      "Epoch 80/100\n",
      "668/668 [==============================] - 0s - loss: 0.6337 - acc: 0.6467 - val_loss: 0.5842 - val_acc: 0.6996\n",
      "Epoch 81/100\n",
      "668/668 [==============================] - 0s - loss: 0.6264 - acc: 0.6572 - val_loss: 0.5865 - val_acc: 0.6996\n",
      "Epoch 82/100\n",
      "668/668 [==============================] - 0s - loss: 0.6490 - acc: 0.6287 - val_loss: 0.5866 - val_acc: 0.7085\n",
      "Epoch 83/100\n",
      "668/668 [==============================] - 0s - loss: 0.6229 - acc: 0.6557 - val_loss: 0.5814 - val_acc: 0.6996\n",
      "Epoch 84/100\n",
      "668/668 [==============================] - 0s - loss: 0.6334 - acc: 0.6362 - val_loss: 0.5787 - val_acc: 0.7130\n",
      "Epoch 85/100\n",
      "668/668 [==============================] - 0s - loss: 0.6156 - acc: 0.6572 - val_loss: 0.5771 - val_acc: 0.7220\n",
      "Epoch 86/100\n",
      "668/668 [==============================] - 0s - loss: 0.6189 - acc: 0.6722 - val_loss: 0.5770 - val_acc: 0.7309\n",
      "Epoch 87/100\n",
      "668/668 [==============================] - 0s - loss: 0.6170 - acc: 0.6662 - val_loss: 0.5765 - val_acc: 0.7040\n",
      "Epoch 88/100\n",
      "668/668 [==============================] - 0s - loss: 0.6204 - acc: 0.6497 - val_loss: 0.5789 - val_acc: 0.7265\n",
      "Epoch 89/100\n",
      "668/668 [==============================] - 0s - loss: 0.6050 - acc: 0.6647 - val_loss: 0.5760 - val_acc: 0.7220\n",
      "Epoch 90/100\n",
      "668/668 [==============================] - 0s - loss: 0.6186 - acc: 0.6602 - val_loss: 0.5732 - val_acc: 0.7085\n",
      "Epoch 91/100\n",
      "668/668 [==============================] - 0s - loss: 0.6268 - acc: 0.6542 - val_loss: 0.5705 - val_acc: 0.7085\n",
      "Epoch 92/100\n",
      "668/668 [==============================] - 0s - loss: 0.6257 - acc: 0.6512 - val_loss: 0.5758 - val_acc: 0.7309\n",
      "Epoch 93/100\n",
      "668/668 [==============================] - 0s - loss: 0.6244 - acc: 0.6497 - val_loss: 0.5743 - val_acc: 0.7265\n",
      "Epoch 94/100\n",
      "668/668 [==============================] - 0s - loss: 0.6069 - acc: 0.6707 - val_loss: 0.5698 - val_acc: 0.7309\n",
      "Epoch 95/100\n",
      "668/668 [==============================] - 0s - loss: 0.6098 - acc: 0.6707 - val_loss: 0.5671 - val_acc: 0.7354\n",
      "Epoch 96/100\n",
      "668/668 [==============================] - 0s - loss: 0.6120 - acc: 0.6632 - val_loss: 0.5631 - val_acc: 0.7354\n",
      "Epoch 97/100\n",
      "668/668 [==============================] - 0s - loss: 0.6135 - acc: 0.6826 - val_loss: 0.5671 - val_acc: 0.7399\n",
      "Epoch 98/100\n",
      "668/668 [==============================] - 0s - loss: 0.6330 - acc: 0.6422 - val_loss: 0.5704 - val_acc: 0.7309\n",
      "Epoch 99/100\n",
      "668/668 [==============================] - 0s - loss: 0.6203 - acc: 0.6482 - val_loss: 0.5729 - val_acc: 0.7354\n",
      "Epoch 100/100\n",
      "668/668 [==============================] - 0s - loss: 0.6060 - acc: 0.6737 - val_loss: 0.5711 - val_acc: 0.7354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23fc93329e8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','name_length','ticket_length']].values\n",
    "y = df[['Survived']].values\n",
    "model.fit(X,y,epochs=100,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.,   1.,  22., ...,   1.,  23.,   9.],\n",
       "       [  1.,   2.,  38., ...,   2.,  51.,   8.],\n",
       "       [  3.,   2.,  26., ...,   1.,  22.,  16.],\n",
       "       ..., \n",
       "       [  3.,   2.,  nan, ...,   1.,  40.,  10.],\n",
       "       [  1.,   1.,  26., ...,   2.,  21.,   6.],\n",
       "       [  3.,   1.,  32., ...,   3.,  19.,   6.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
